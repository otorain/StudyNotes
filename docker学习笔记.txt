##安装
ubuntu里安装最新版本的方法
$ sudo apt-get install apt-transport-https
$ sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys 36A1D7869245C8950F966E92D8576A8BA88D21E9
$ sudo bash -c "echo deb https://get.docker.io/ubuntu docker main > /etc/apt/sources.list.d/docker.list"
$ sudo apt-get update
$ sudo apt-get install -y lxc-docker
在安装了Docker官方软件源后，若需要更新Docker软件版本，只需要执行以下命令即可升级：
$ sudo apt-get update -y lxc-docker

现在又有了更简单的方法
sudo apt-get innstal docker.io -y

官方安装例子:
Get the latest Docker package.
$ wget -qO- https://get.docker.com/ | sh

#Note: If your company is behind a filtering proxy, you may find that the apt-key command fails for the Docker repo during installation. To work around this, add the key directly using the following:

$ wget -qO- https://get.docker.com/gpg | sudo apt-key add -


Mac安装
在Mac OS上使用Docker，同样需要Boot2Docker工具的支持。主要步骤如下：
1）下载最新官方Docker for OS X Installer。读者可以从https://docs.docker.com/installation/mac/下载。
2）双击运行安装包。这个过程将安装一个VirtualBox虚拟机、Docker本身以及Boot2Docker管理工具，如图2-4所示。
3）安装成功后，找到Boot2Docker（Mac系统的Application或“应用”文件夹中）并运行它。现在进行Boot2Docker的初始化：
$ boot2docker init
$ boot2docker start
$ $(boot2docker shellinit)
读者将看到虚拟机在命令行窗口中启动运行，并显示Docker的启动信息，则说明Docker安装成功。
当虚拟机初始化完毕后，可以使用boot2docker stop和boot2docker start来控制它。
注意：如果在命令行中看到如下提示信息：To connect the Docker client to the Docker daemon, please set: export  DOCKER_HOST=tcp://192.168.59.103:2375可以执行提示信息中的语句：
exportDOCKER_HOST=tcp://192.168.59.103：2375。此语句的作用是在系统环境变量中设置Docker的主机地址。

-----------------------
不想一直sudo的话，把用户加入docker组
$ sudo usermod -aG docker jojo
注销退出后就生效


-----------------------
查看一个容器的完整支持
$ docker run -it --rm mysql:5.7 --verbose --help

------------------------
更换中科大的源
https://lug.ustc.edu.cn/wiki/mirrors/help/docker
新版的 Docker 使用 /etc/docker/daemon.json（Linux） 或者 %programdata%\dockerconsole.log(onfig\daemon.json（Windows） 来配置 Daemon。

mac 版在 ~/.docker/daemon.json

请在该配置文件中加入（没有该文件的话，请先建一个）：

{
  "registry-mirrors": ["https://docker.mirrors.ustc.edu.cn"]
}

Docker Daemon configuration file 文档： https://docs.docker.com/engine/reference/commandline/dockerd/#/daemon-configuration-file

Docker for Windows 文档: https://docs.docker.com/docker-for-windows/#/docker-daemon

)

阿里云自己也有加速源，同样修改配置文件配置好后，执行重启
$ sudo systemctl daemon-reload
$ sudo systemctl restart docker
------------------------



##三大核心概念 镜像(只读，相当于模板，限制了边界), 容器(镜像跑起来的一个实例，里面的操作就在容器里玩), 仓库（简单理解就是github一样存放镜像就好）

##拉镜像
$ sudo docker pull ubuntu
这样就会拉下ubuntu:lastest

$ sudo docker pull ubuntu: 14.04
下载指定版本的ubuntu

默认是从registry.hub.docker.com这个源下载的，也可以手动指定从哪个源下
$ sudo docker pull dl.dockerpool.com:5000/ ubuntu

下载完就可以用镜像创建一个容器了, 例如用ubuntu的/bin/bash
$ sudo docker run -t -i ubuntu /bin/bash

查看镜像信息
$ sudo docker images
可以看到诸如此类的信息,其中id标明唯一
REPOSITORY                    TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
kalilinux/kali-linux-docker   latest              e49f6054690a        9 weeks ago         420.3 MB

$ docker history
查看历史信息 

有时打个tag会挺方便的
$ sudo docker tag dl.dockerpool.com:5000/ubuntu:latest ubuntu:latest
就打出了一个ubuntu:latest的标签，他和源的id是一样的

docker inspect id可以产看镜像的详细信息

docker search TERM 可以搜索仓库里的镜像
例如 $ docker search mysql

删除镜像,
docker rmi [IMAGE] #iamge可以是tag或者id
有时容器在跑时删不了可以加-f参数

查看所有容器
$ docker ps -a

删除容器
docker rm 容器id


导入导出镜像
导出
$ sudo docker save -o ubuntu_14.04.tar
导入
$ sudo docker load --input ubuntu_14.04.tar
or
$ sudo docker load < ubuntu_14.04.tar


##!!!容器
容器相比起镜像，他就是一个轻量实例，有额外的可写入文件层

新建容器
$ sudo docker create -it ubuntu:lastest
$ sudo docker ps -a
create完可以用start启用他, docker run相当于先create再start

当利用docker run来创建并启动容器时，Docker在后台运行的标准操作包括：   
•检查本地是否存在指定的镜像，不存在就从公有仓库下载。
•利用镜像创建并启动一个容器。
•分配一个文件系统，并在只读的镜像层外面挂载一层可读写层。
•从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去。
•从地址池配置一个IP地址给容器。
•执行用户指定的应用程序。
•执行完毕后容器被终止。

$ sudo docker run -ti ubuntu /bin/bash #创建了一个可交互的终端
t选项就是分配一个伪终端pseudo-tty, i参数就是标准输入保持打开

让容器在Daemonized形式后台运行
$ sudo docker run -d ubuntu /bin/sh -c "loop do sth"
ce554xxxxxx #执行完后会返回一个唯一id

用logs id查看上面输出的信息
$ sudo docker logs ce5

终止容器 docker stop
例如上面的ce5容器
$ docker stop ce5

$ docker -a -q #可以列出所有stop状态的容器
$ docker start ce5 #又再打开
$ docker restart ce5 #先stop再start

进入容器
如果进入daemon状态的容器，大家都看不到他的信息，这时可以用docker attach或docker exec或nsenter等，都和linux差不多
$ docker attach id或容器names
$ docker exec -ti 容器id /bin/bash

停止了的容器，可以先start在attach
$ docker start 容器id
$ docker attach 容器id

导入导出容器
导出容器
$ docker export 容器id > xxx.tar

导出的文件可以使用docker import导入，成为镜像
$ cat xxx.tar | sudo docker import -test/ubuntu:v1.0

!!容器数据管理,主要有两种方式:
·数据卷
·数据卷容器

数据卷
数据卷是一个可供容器使用的特殊目录，它绕过文件系统，可以提供很多有用的特性：
•数据卷可以在容器之间共享和重用。
•对数据卷的修改会立马生效。
•对数据卷的更新，不会影响镜像。
•卷会一直存在，直到没有容器使用。数据卷的使用，类似于Linux下对目录或文件进行mount操作。

docker run时，使用-v标记可以创建一个数据卷，多个v可以创建多个
使用training/webapp镜像创建一个容器
$ sudo docker run -d -P --name web -v /webapp training/webapp python app.py
-P是允许外部访问容器暴露的端口

用-v可以挂在本地已有的目录到容器里做数据卷, 这个是加载主机/src/webapp到容器的/opt/webapp目录
$ sudo docker run -d -P --name web -v /src/webapp:/opt/webapp training/webapp python app.py

目录不存在是docker会自动创建, 默认挂载权限是rw,可以变只读ro
$ sudo docker run -d -P --name web -v /src/webapp:/opt/webapp:ro training/webapp python app.py

-v也可以挂载单个文件做数据卷
$ sudo docker run --rm -it -v ~/.bash_history:/.bash_history ubuntu /bin/bash #这样就可以记录下容器的bash历史了


数据卷容器
用途是让容器之间共享一些持续更新的数据, 数据卷容器本质就是一个普通容器，专门用它提供数据卷供其他容器挂载使用

例: 创建一个数据卷容器dbdata并挂一个数据卷到/dbdata
$ sudo docker run -it -v /dbdata --name dbdata ubuntu
然后可以用--volumes-from挂载dbdata容器里面的数据卷
$ sudo docker run -it --volumes-from dbdata --name db1 ubuntu
$ sudo docker run -it --volumes-from dbdata --name db2 ubuntu
此时容器db1和db2都挂载同一个数据卷到/dbdata目录，三个容器任何一方在该目录写入，其他容器都可以看到
还可以从已经挂载过的容器创建新的容器，使用同一个数据卷容器
$ sudo docker run -d --name db3 --volumes-from db1 training/postgres

利用数据卷容器迁移数据
备份上面例子的dbdata
$ sudo docker run -volumes-from dbdata -v $(pwd):/backup --name worker ubuntu tar cvf /backup/backup.tar /dbdata
首先利用ubuntu镜像创建了一个容器worker。使用--volumes-from dbdata参数来让worker容器挂载dbdata容器的数据卷；使用-v $(pwd):/backup参数来挂载本地的当前目录到worker容器的/backup目录。worker容器启动后，使用了tar cvf/backup/backup.tar/dbdata命令来将/dbdata下内容备份为容器内的/backup/backup.tar，即宿主主机当前目录下的backup.tar。

恢复数据到一个容器
首先创建一个带有数据卷的容器dbdata2：
$ sudo docker run -v /dbdata --name dbdata2 ubuntu /bin/bash
然后创建另一个新的容器，挂载dbdata2的容器，并使用untar解压备份文件到所挂载的容器卷中即可：
$ sudo docker run --volumes-from dbdata2 -v $(pwd):/backup busybox tar xvf/backup/backup.tar

--------------------------
更新镜像两种方式

1. 在容器里执行后commit
$ docker run -t -i ubuntu:15.10 /bin/bash
root@e218edb10161: apt-get update
root@e218edb10161: exit

容器里跑完东西后
$ docker commit -m="has update" -a="runoob" e218edb10161 runoob/ubuntu:v2
-m 是commit message
-a 是作者
e218edb10161 是进入容器操作时root@xxxxx里面的这个xxxxx


2. 以Dockerfile的方式是去build一个
创建Dockerfile:

FROM    centos:6.7
MAINTAINER      Fisher "fisher@sudops.com"

RUN     /bin/echo 'root:123456' |chpasswd
RUN     useradd runoob
RUN     /bin/echo 'runoob:123456' |chpasswd
RUN     /bin/echo -e "LANG=\"en_US.UTF-8\"" >/etc/default/local
EXPOSE  22
EXPOSE  80
CMD     /usr/sbin/sshd -D

###
每一个指令都会在镜像上创建一个新的层，每一个指令的前缀都必须是大写的。

第一条FROM，指定使用哪个镜像源

RUN 指令告诉docker 在镜像内执行命令，安装了什么。。。

然后，我们使用 Dockerfile 文件，通过 docker build 命令来构建一个镜像。

$ docker build -t runoob/centos:6.7 .


--------------------------
网络端口映射
runoob@runoob:~$ docker run -d -P training/webapp python app.py

-P 参数创建一个容器，使用 docker ps 来看到端口5000绑定主机端口32768, 随机创建端口让他绑定的意思
-p 小写p是指定端口, 例如:
$ docker run -d -p 5000:5000 training/webapp python app.py

还可以指定具体的网络地址
$ docker run -d -p 127.0.0.1:5001:5000 training/webapp python app.py
默认tcp, 可指定udp

$ docker run -d -p 127.0.0.1:5001:5000/udp training/webapp python app.py

端口映射并不是唯一把 docker 连接到另一个容器的方法。

docker有一个连接系统允许将多个容器连接在一起，共享连接信息。

docker连接会创建一个父子关系，其中父容器可以看到子容器的信息。

容器命名
当我们创建一个容器的时候，docker会自动对它进行命名。另外，我们也可以使用--name标识来命名容器，例如：
$ docker run -d -P --name runoob training/webapp python app.py
43780a6eabaaf14e590b6e849235c75f3012995403f97749775e38436db9a441

我们可以使用 docker ps 命令来查看容器名称。
$ docker ps -l
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS                     NAMES
43780a6eabaa        training/webapp     "python app.py"     3 minutes ago       Up 3 minutes        0.0.0.0:32769->5000/tcp   runoob

--------------------------
nginx实例
$ docker pull nginx

创建几个挂载点
$ docker run -p 80:80 --name mynginx -v $PWD/www:/www -v $PWD/conf/nginx.conf:/etc/nginx/
命令说明：

-p 80:80：将容器的80端口映射到主机的80端口
--name mynginx：将容器命名为mynginx
-v $PWD/www:/www：将主机中当前目录下的www挂载到容器的/www
-v $PWD/conf/nginx.conf:/etc/nginx/nginx.conf：将主机中当前目录下的nginx.conf挂载到容器的/etc/nginx/nginx.conf
-v $PWD/logs:/wwwlogs：将主机中当前目录下的logs挂载到容器的/wwwlogs

--------------------------
mysql 实例
runoob@runoob:~/mysql$ docker pull mysql:5.6

runoob@runoob:~$ mkdir -p ~/mysql/data ~/mysql/logs ~/mysql/conf
#
data目录将映射为mysql容器配置的数据文件存放路径

logs目录将映射为mysql容器的日志目录

conf目录里的配置文件将映射为mysql容器的配置文件

进入创建的mysql目录，创建Dockerfile

运行

runoob@runoob:~/mysql$ docker run -p 3306:3306 --name mymysql -v $PWD/conf:/etc/mysql/conf.d -v $PWD/logs:/logs -v $PWD/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.6
#
-p 3306:3306：将容器的 3306 端口映射到主机的 3306 端口。

-v -v $PWD/conf:/etc/mysql/conf.d：将主机当前目录下的 conf/my.cnf 挂载到容器的 /etc/mysql/my.cnf。

-v $PWD/logs:/logs：将主机当前目录下的 logs 目录挂载到容器的 /logs。

-v $PWD/data:/var/lib/mysql ：将主机当前目录下的data目录挂载到容器的 /var/lib/mysql 。

-e MYSQL_ROOT_PASSWORD=123456：初始化 root 用户的密码。


--------------------------
搭建本地私有仓库
通过官方registry镜像搭建本地私有仓库
$ docker run -d -p 5000:5000 registry

默认保存在 /tmp/registry 可以指定其他位置
$ docker run -d -p 5000:5000 -v /opt/data/registry:/tmp/registry registry

例如仓库机ip是 10.0.2.2:5000, 把远端标签打到本地
$ docker tag ubuntu:14.04 10.0.2.2:5000/test
$ docker push #上传就会自动用仓库机
$ curl http://10.0.2.2:5000/v1/search #用curl可以简单查看远端有什么镜像

现在什么都https，除了配证书也可以指定环境变量 
$ DOCKER_OPTS="--insecure-registry 10.0.2.2:5000 #加入信任



--------------------------
Docker查看占用资源

$ docker stats

只显示CPU 和 内存
$ docker stats --format "table {{.Name}}\t{{.CPUPerc}}\t{{.MemUsage}}"

JSON输出
$ docker stats --no-stream --format \
    "{\"container\":\"{{ .Container }}\",\"memory\":{\"raw\":\"{{ .MemUsage }}\",\"percent\":\"{{ .MemPerc }}\"},\"cpu\":\"{{ .CPUPerc }}\"}"
--------------------------
Compose docker-compose

mac版和win版的App自带，linux版可以用pip或最好用二进制安装

$ sudo curl -L "https://github.com/docker/compose/releases/download/1.23.1/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose

$ sudo chomod +x docker-compose

$ docker-compose --version

$ docker-compose migrate-to-labels #升级

删除直接删除二进制就好, 还可以参考安装completion [https://docs.docker.com/compose/completion/]()

docker-compose [-f=<arg>...] [options] [COMMAND] [ARGS...]
命令选项
-f, --file FILE 指定使用的 Compose 模板文件，默认为 docker-compose.yml，可以多次指定。

-p, --project-name NAME 指定项目名称，默认将使用所在目录名称作为项目名。

--x-networking 使用 Docker 的可拔插网络后端特性

--x-network-driver DRIVER 指定网络后端的驱动，默认为 bridge

--verbose 输出更多调试信息。

-v, --version 打印版本并退出。

# build
格式为 docker-compose build [options] [SERVICE...]。

构建（重新构建）项目中的服务容器。

服务容器一旦构建后，将会带上一个标记名，例如对于 web 项目中的一个 db 容器，可能是 web_db。

可以随时在项目目录下运行 docker-compose build 来重新构建服务。

选项包括：

--force-rm 删除构建过程中的临时容器。

--no-cache 构建镜像过程中不使用 cache（这将加长构建过程）。

--pull 始终尝试通过 pull 来获取更新版本的镜像。

#run
格式为 docker-compose run [options] [-p PORT...] [-e KEY=VAL...] SERVICE [COMMAND] [ARGS...]。

在指定服务上执行一个命令。

例如：

$ docker-compose run ubuntu ping docker.com
将会启动一个 ubuntu 服务容器，并执行 ping docker.com 命令。

默认情况下，如果存在关联，则所有关联的服务将会自动被启动，除非这些服务已经在运行中。

该命令类似启动容器后运行指定的命令，相关卷、链接等等都将会按照配置自动创建。

两个不同点：

给定命令将会覆盖原有的自动运行命令；

不会自动创建端口，以避免冲突。

如果不希望自动启动关联的容器，可以使用 --no-deps 选项，例如

$ docker-compose run --no-deps web python manage.py shell

选项：

-d 后台运行容器。

--name NAME 为容器指定一个名字。

--entrypoint CMD 覆盖默认的容器启动指令。

-e KEY=VAL 设置环境变量值，可多次使用选项来设置多个环境变量。

-u, --user="" 指定运行容器的用户名或者 uid。

--no-deps 不自动启动关联的服务容器。

--rm 运行命令后自动删除容器，d 模式下将忽略。

-p, --publish=[] 映射容器端口到本地主机。

--service-ports 配置服务端口并映射到本地主机。

-T 不分配伪 tty，意味着依赖 tty 的指令将无法运行。

#scale 大杀器!! 
格式为 docker-compose scale [options] [SERVICE=NUM...]。

设置指定服务运行的容器个数。

通过 service=num 的参数来设置数量。例如：

$ docker-compose scale web=3 db=2
将启动 3 个容器运行 web 服务，2 个容器运行 db 服务。

一般的，当指定数目多于该服务当前实际运行容器，将新创建并启动容器；反之，将停止容器。

选项：

-t, --timeout TIMEOUT 停止容器时候的超时（默认为 10 秒）。

还可以在 docker compose run xxx --scale web=3

配置文件version 3里舍弃了scacle的配置项，都在启动命令里配置 

#rm
格式为 docker-compose rm [options] [SERVICE...]。

删除所有（停止状态的）服务容器。推荐先执行 docker-compose stop 命令来停止容器。

选项：

-f, --force 强制直接删除，包括非停止状态的容器。一般尽量不要使用该选项。

-v 删除容器所挂载的数据卷。

#kill
格式为 docker-compose kill [options] [SERVICE...]。

通过发送 SIGKILL 信号来强制停止服务容器。

支持通过 -s 参数来指定发送的信号，例如通过如下指令发送 SIGINT 信号。

$ docker-compose kill -s SIGINT

#logs
格式为 docker-compose logs [options] [SERVICE...]。

查看服务容器的输出。默认情况下，docker-compose 将对不同的服务输出使用不同的颜色来区分。可以通过 --no-color 来关闭颜色。

该命令在调试问题的时候十分有用。

#start
格式为 docker-compose start [SERVICE...]。

启动已经存在的服务容器。

#stop
格式为 docker-compose stop [options] [SERVICE...]。

停止已经处于运行状态的容器，但不删除它。通过 docker-compose start 可以再次启动这些容器。

选项：

-t, --timeout TIMEOUT 停止容器时候的超时（默认为 10 秒）。

#top
查看各个服务容器内运行的进程。

#unpause
格式为 docker-compose unpause [SERVICE...]。

恢复处于暂停状态中的服务。


# up
格式为 docker-compose up [options] [SERVICE...]。

该命令十分强大，它将尝试自动完成包括构建镜像，（重新）创建服务，启动服务，并关联服务相关容器的一系列操作。

链接的服务都将会被自动启动，除非已经处于运行状态。

可以说，大部分时候都可以直接通过该命令来启动一个项目。

默认情况，docker-compose up 启动的容器都在前台，控制台将会同时打印所有容器的输出信息，可以很方便进行调试。

当通过 Ctrl-C 停止命令时，所有容器将会停止。

如果使用 docker-compose up -d，将会在后台启动并运行所有的容器。一般推荐生产环境下使用该选项。

默认情况，如果服务容器已经存在，docker-compose up 将会尝试停止容器，然后重新创建（保持使用 volumes-from 挂载的卷），以保证新启动的服务匹配 docker-compose.yml 文件的最新内容。如果用户不希望容器被停止并重新创建，可以使用 docker-compose up --no-recreate。这样将只会启动处于停止状态的容器，而忽略已经运行的服务。如果用户只想重新部署某个服务，可以使用 docker-compose up --no-deps -d <SERVICE_NAME> 来重新创建服务并后台停止旧服务，启动新服务，并不会影响到其所依赖的服务。

选项：

-d 在后台运行服务容器。

--no-color 不使用颜色来区分不同的服务的控制台输出。

--no-deps 不启动服务所链接的容器。

--force-recreate 强制重新创建容器，不能与 --no-recreate 同时使用。

--no-recreate 如果容器已经存在了，则不重新创建，不能与 --force-recreate 同时使用。

--no-build 不自动构建缺失的服务镜像。

-t, --timeout TIMEOUT 停止容器时候的超时（默认为 10 秒）。



--------------------------
Compose模板文件

Compose 模板文件
模板文件是使用 Compose 的核心，涉及到的指令关键字也比较多。但大家不用担心，这里面大部分指令跟 docker run 相关参数的含义都是类似的。

默认的模板文件名称为 docker-compose.yml，格式为 YAML 格式。

version: "3"

services:
  webapp:
    image: examples/web
    ports:
      - "80:80"
    volumes:
      - "/data"
注意每个服务都必须通过 image 指令指定镜像或 build 指令（需要 Dockerfile）等来自动构建生成镜像。

如果使用 build 指令，在 Dockerfile 中设置的选项(例如：CMD, EXPOSE, VOLUME, ENV 等) 将会自动被获取，无需在 docker-compose.yml 中再次设置。

下面分别介绍各个指令的用法。

#build
指定 Dockerfile 所在文件夹的路径（可以是绝对路径，或者相对 docker-compose.yml 文件的路径）。 Compose 将会利用它自动构建这个镜像，然后使用这个镜像。

version: '3'
services:

  webapp:
    build: ./dir

你也可以使用 context 指令指定 Dockerfile 所在文件夹的路径。

使用 dockerfile 指令指定 Dockerfile 文件名。

使用 arg 指令指定构建镜像时的变量。

version: '3'
services:

  webapp:
    build:
      context: ./dir
      dockerfile: Dockerfile-alternate
      args:
        buildno: 1
使用 cache_from 指定构建镜像的缓存

build:
  context: .
  cache_from:
    - alpine:latest
    - corp/web_app:3.14
cap_add, cap_drop
指定容器的内核能力（capacity）分配。

例如，让容器拥有所有能力可以指定为：

cap_add:
  - ALL
去掉 NET_ADMIN 能力可以指定为：

cap_drop:
  - NET_ADMIN
command
覆盖容器启动后默认执行的命令。

command: echo "hello world"
configs
仅用于 Swarm mode，详细内容请查看 Swarm mode 一节。

cgroup_parent
指定父 cgroup 组，意味着将继承该组的资源限制。

例如，创建了一个 cgroup 组名称为 cgroups_1。

cgroup_parent: cgroups_1
container_name
指定容器名称。默认将会使用 项目名称_服务名称_序号 这样的格式。

container_name: docker-web-container
注意: 指定容器名称后，该服务将无法进行扩展（scale），因为 Docker 不允许多个容器具有相同的名称。

deploy
仅用于 Swarm mode，详细内容请查看 Swarm mode 一节

devices
指定设备映射关系。

devices:
  - "/dev/ttyUSB1:/dev/ttyUSB0"
depends_on
解决容器的依赖、启动先后的问题。以下例子中会先启动 redis db 再启动 web

version: '3'

services:
  web:
    build: .
    depends_on:
      - db
      - redis

  redis:
    image: redis

  db:
    image: postgres
注意：web 服务不会等待 redis db 「完全启动」之后才启动。

dns
自定义 DNS 服务器。可以是一个值，也可以是一个列表。

dns: 8.8.8.8

dns:
  - 8.8.8.8
  - 114.114.114.114
dns_search
配置 DNS 搜索域。可以是一个值，也可以是一个列表。

dns_search: example.com

dns_search:
  - domain1.example.com
  - domain2.example.com
tmpfs
挂载一个 tmpfs 文件系统到容器。

tmpfs: /run
tmpfs:
  - /run
  - /tmp
env_file
从文件中获取环境变量，可以为单独的文件路径或列表。

如果通过 docker-compose -f FILE 方式来指定 Compose 模板文件，则 env_file 中变量的路径会基于模板文件路径。

如果有变量名称与 environment 指令冲突，则按照惯例，以后者为准。

env_file: .env

env_file:
  - ./common.env
  - ./apps/web.env
  - /opt/secrets.env
环境变量文件中每一行必须符合格式，支持 # 开头的注释行。

# common.env: Set development environment
PROG_ENV=development
environment
设置环境变量。你可以使用数组或字典两种格式。

只给定名称的变量会自动获取运行 Compose 主机上对应变量的值，可以用来防止泄露不必要的数据。

environment:
  RACK_ENV: development
  SESSION_SECRET:

environment:
  - RACK_ENV=development
  - SESSION_SECRET
如果变量名称或者值中用到 true|false，yes|no 等表达 布尔 含义的词汇，最好放到引号里，避免 YAML 自动解析某些内容为对应的布尔语义。这些特定词汇，包括

y|Y|yes|Yes|YES|n|N|no|No|NO|true|True|TRUE|false|False|FALSE|on|On|ON|off|Off|OFF
expose
暴露端口，但不映射到宿主机，只被连接的服务访问。

仅可以指定内部端口为参数

expose:
 - "3000"
 - "8000"
external_links
注意：不建议使用该指令。

链接到 docker-compose.yml 外部的容器，甚至并非 Compose 管理的外部容器。

external_links:
 - redis_1
 - project_db_1:mysql
 - project_db_1:postgresql
extra_hosts
类似 Docker 中的 --add-host 参数，指定额外的 host 名称映射信息。

extra_hosts:
 - "googledns:8.8.8.8"
 - "dockerhub:52.1.157.61"
会在启动后的服务容器中 /etc/hosts 文件中添加如下两条条目。

8.8.8.8 googledns
52.1.157.61 dockerhub
healthcheck
通过命令检查容器是否健康运行。

healthcheck:
  test: ["CMD", "curl", "-f", "http://localhost"]
  interval: 1m30s
  timeout: 10s
  retries: 3
image
指定为镜像名称或镜像 ID。如果镜像在本地不存在，Compose 将会尝试拉取这个镜像。

image: ubuntu
image: orchardup/postgresql
image: a4bc65fd
labels
为容器添加 Docker 元数据（metadata）信息。例如可以为容器添加辅助说明信息。

labels:
  com.startupteam.description: "webapp for a startup team"
  com.startupteam.department: "devops department"
  com.startupteam.release: "rc3 for v1.0"
links
注意：不推荐使用该指令。

logging
配置日志选项。

logging:
  driver: syslog
  options:
    syslog-address: "tcp://192.168.0.42:123"
目前支持三种日志驱动类型。

driver: "json-file"
driver: "syslog"
driver: "none"
options 配置日志驱动的相关参数。

options:
  max-size: "200k"
  max-file: "10"
network_mode
设置网络模式。使用和 docker run 的 --network 参数一样的值。

network_mode: "bridge"
network_mode: "host"
network_mode: "none"
network_mode: "service:[service name]"
network_mode: "container:[container name/id]"
networks
配置容器连接的网络。

version: "3"
services:

  some-service:
    networks:
     - some-network
     - other-network

networks:
  some-network:
  other-network:
pid
跟主机系统共享进程命名空间。打开该选项的容器之间，以及容器和宿主机系统之间可以通过进程 ID 来相互访问和操作。

pid: "host"
ports
暴露端口信息。

使用宿主端口：容器端口 (HOST:CONTAINER) 格式，或者仅仅指定容器的端口（宿主将会随机选择端口）都可以。

ports:
 - "3000"
 - "8000:8000"
 - "49100:22"
 - "127.0.0.1:8001:8001"
注意：当使用 HOST:CONTAINER 格式来映射端口时，如果你使用的容器端口小于 60 并且没放到引号里，可能会得到错误结果，因为 YAML 会自动解析 xx:yy 这种数字格式为 60 进制。为避免出现这种问题，建议数字串都采用引号包括起来的字符串格式。

secrets
存储敏感数据，例如 mysql 服务密码。

version: "3.1"
services:

mysql:
  image: mysql
  environment:
    MYSQL_ROOT_PASSWORD_FILE: /run/secrets/db_root_password
  secrets:
    - db_root_password
    - my_other_secret

secrets:
  my_secret:
    file: ./my_secret.txt
  my_other_secret:
    external: true
security_opt
指定容器模板标签（label）机制的默认属性（用户、角色、类型、级别等）。例如配置标签的用户名和角色名。

security_opt:
    - label:user:USER
    - label:role:ROLE
stop_signal
设置另一个信号来停止容器。在默认情况下使用的是 SIGTERM 停止容器。

stop_signal: SIGUSR1
sysctls
配置容器内核参数。

sysctls:
  net.core.somaxconn: 1024
  net.ipv4.tcp_syncookies: 0

sysctls:
  - net.core.somaxconn=1024
  - net.ipv4.tcp_syncookies=0
ulimits
指定容器的 ulimits 限制值。

例如，指定最大进程数为 65535，指定文件句柄数为 20000（软限制，应用可以随时修改，不能超过硬限制） 和 40000（系统硬限制，只能 root 用户提高）。

  ulimits:
    nproc: 65535
    nofile:
      soft: 20000
      hard: 40000
volumes
数据卷所挂载路径设置。可以设置宿主机路径 （HOST:CONTAINER） 或加上访问模式 （HOST:CONTAINER:ro）。

该指令中路径支持相对路径。

volumes:
 - /var/lib/mysql
 - cache/:/tmp/cache
 - ~/configs:/etc/configs/:ro
其它指令
此外，还有包括 domainname, entrypoint, hostname, ipc, mac_address, privileged, read_only, shm_size, restart, stdin_open, tty, user, working_dir 等指令，基本跟 docker run 中对应参数的功能一致。

指定服务容器启动后执行的入口文件。

entrypoint: /code/entrypoint.sh
指定容器中运行应用的用户名。

user: nginx
指定容器中工作目录。

working_dir: /code
指定容器中搜索域名、主机名、mac 地址等。

domainname: your_website.com
hostname: test
mac_address: 08-00-27-00-0C-0A
允许容器中运行一些特权命令。

privileged: true
指定容器退出后的重启策略为始终重启。该命令对保持服务始终运行十分有效，在生产环境中推荐配置为 always 或者 unless-stopped。

restart: always
以只读模式挂载容器的 root 文件系统，意味着不能对容器内容进行修改。

read_only: true
打开标准输入，可以接受外部输入。

stdin_open: true
模拟一个伪终端。

tty: true
读取变量
Compose 模板文件支持动态读取主机的系统环境变量和当前目录下的 .env 文件中的变量。

例如，下面的 Compose 文件将从运行它的环境中读取变量 ${MONGO_VERSION} 的值，并写入执行的指令中。

version: "3"
services:

db:
  image: "mongo:${MONGO_VERSION}"
如果执行 MONGO_VERSION=3.2 docker-compose up 则会启动一个 mongo:3.2 镜像的容器；如果执行 MONGO_VERSION=2.8 docker-compose up 则会启动一个 mongo:2.8 镜像的容器。

若当前目录存在 .env 文件，执行 docker-compose 命令时将从该文件中读取变量。

在当前目录新建 .env 文件并写入以下内容。

# 支持 # 号注释
MONGO_VERSION=3.6
执行 docker-compose up 则会启动一个 mongo:3.6 镜像的容器。

--------------------------



############### Emby ###############
sudo docker run -d \
    --volume /media/jojo/Media/config \
    --volume /media/jojo/Media/media/电影 \
    --volume /media/jojo/Media/media/动画 \
    --device /dev/dri/renderD128 \
    --publish 8096:8096 \
    --publish 8920:8920 \
    --env UID=1000 \
    --env GID=100 \
    --env GIDLIST=100 \
    emby/embyserver:latest

------------------------
############### adminer 管理mysql gui###############
$ docker run --link just-mysql:db -p 8080:8080 adminer

-----------------------
有时删了镜像但还是有些暂停的容器没清除时
docker ps -a看一下id
docker ps -a | grep 镜像id | awk '{print $1}' | xargs docker rm

现在可以 docker rm $(docker ps -a -q)


-----------------------
Swarm Mode

主要概念是 manager 和 worker节点，基本管理操作在manager, worker一般join完就ok了，发现服务用etcd。本地模拟可以使用docker-machine虚拟多台虚拟主机做测试

来:

$ docker-machine create -d virtualbox manager
$ docker-machine ssh manager
$ docker swarm init --advertise-addr 192.168.99.100
Swarm initialized: current node (dxn1zf6l61qsb1josjja83ngz) is now a manager.
To add a worker to this swarm, run the following command:
    docker swarm join \
		--token SWMTKN-1-49nj1cmql0jkz5s954yi3oex3nedyz0fb0xx14ie39trti4wxv-8vxv8rssmk743ojnwacrr2e7c \
		192.168.99.100:2377
To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.

如果你的 Docker 主机有多个网卡，拥有多个 IP，必须使用 --advertise-addr 指定 IP。

执行 docker swarm init 命令的节点自动成为管理节点。


开多两个worker并加入到manager

$ docker-machine create -d virtualbox worker1
$ docker-machine create -d virtualbox worker2

$ docker-machine ssh worker1
两台都join
$ docker swarm join \   
		--token SWMTKN-1-49nj1cmql0jkz5s954yi3oex3nedyz0fb0xx14ie39trti4wxv-8vxv8rssmk743ojnwacrr2e7c \
		192.168.99.100:2377

然后ssh进入回manager会发现多了两台worker
$ docker node ls

在管理节点开个service 
$ docker service create --replicas 3 -p 80:80 --name nginx nginx:1.13.7-alpine
3个nginx实例

$ docker service ls 可以列出所有searvice
$ docker service ps nginx 查看某个service详情
$ docker service logs nginx 查看某个service的log
$ docker service scale nginx=5 服务伸缩，可以把nginx扩展到5个
$ docker service rm nginx 删除某个service

docker service create 一次只能启动一个，可以用deploy 使用compose文件



------------------
在docker-machine里重启docker

$ sudo /etc/init.d/docker  restart



-----------------
要手动login不设https的源，ignore时候的是指
$ vi /etc/docker/daemon.json

{
  "insecure-registries" : ["docker.yueren.io", "120.79.45.78"]
}

$ sudo /etc/init.d/docker restart

---------------
阿里云安装kubeadm kubelet kubectl的麻烦事

官方推荐ubuntu用以下方式安装

apt-get update && apt-get install -y apt-transport-https curl
curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -
cat <<EOF >/etc/apt/sources.list.d/kubernetes.list
deb https://apt.kubernetes.io/ kubernetes-xenial main
EOF
apt-get update
apt-get install -y kubelet kubeadm kubectl
apt-mark hold kubelet kubeadm kubectl

其中更新源或者实际安装包都需要翻墙

$ pip install shadowsocks
然后配置 对应json, 之前使用的服务用26xxx的端口失败(但配置本地开发可用)，问朋友用一个15xxx的端口成功了, 不知道是什么限制

$ sudo apt-get install privoxy
$ vim /etc/privoxy/config

改listen-address地址，最后在加一行, 记得后面有个点
forward-socks5 / 127.0.0.1:1080 . 

$ sudo service restart privoxy

重启后 http_proxy=http://127.0.0.1:8118 都会代理到ss的1080

curl等翻墙已经ok，其实不用http_proxy的话curl还可以还可以这样翻墙

$ curl --socks 127.0.0.1:1080 ipinfo.io


然后apt-get update走的是系统层级代理，不想用配置文件的话就这样写
$ sudo apt-get -o Acquire::http::proxy="http://127.0.0.1:8118/" update

或者使用国内源，这个相当于修改这个文件 ustc

cat <<EOF > /etc/apt/sources.list.d/kubernetes.list
deb http://mirrors.ustc.edu.cn/kubernetes/apt kubernetes-xenial main
EOF

apt-get update && apt-get install -y apt-transport-https curl
curl -s http://packages.faasx.com/google/apt/doc/apt-key.gpg | sudo apt-key add -

cat <<EOF > /etc/apt/sources.list.d/kubernetes.list
deb http://mirrors.ustc.edu.cn/kubernetes/apt kubernetes-xenial main
EOF

apt-get update
apt-get install -y kubelet kubeadm kubectl
apt-mark hold kubelet kubeadm kubectl

---------------
